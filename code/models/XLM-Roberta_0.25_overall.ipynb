{"cells":[{"cell_type":"markdown","metadata":{"id":"-4OUvVfQLgR4"},"source":["\n","XLM-Roberta on multilingual text\n","\n","- Training data + augmentation data\n","- Weighted loss = 25% Overall + (50% / 6 = 12.5%) for each of the remaining 6 labels\n","- Model parameter file: XLM_Roberta_0.50_overall_loss.pth"]},{"cell_type":"markdown","metadata":{"id":"Bhj8tK3WESKl"},"source":["0. Install and import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q-Mlm41yMmLS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653865920784,"user_tz":420,"elapsed":33775,"user":{"displayName":"Leo Ly","userId":"15125541943939299124"}},"outputId":"ecfda100-520f-4c56-bd5f-a05fd4c66ee5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 10.9 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 1.9 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 32.4 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 5.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 12.4 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n"]}],"source":["## install libraries\n","\n","!pip install transformers\n","!pip install sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28168,"status":"ok","timestamp":1653865948939,"user":{"displayName":"Leo Ly","userId":"15125541943939299124"},"user_tz":420},"id":"lH_HtKSJLeWh","outputId":"8837f4da-90e8-42bf-d12f-e04e107911c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import random\n","import json\n","import regex as re\n","\n","import matplotlib.pyplot as plt\n","import os\n","import sentencepiece\n","import torch\n","import torch.nn as nn\n","from transformers import AutoTokenizer\n","from transformers import AdamW\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import TensorDataset, DataLoader\n","from transformers import XLMRobertaConfig, XLMRobertaModel, XLMRobertaTokenizer\n","\n","torch.cuda.empty_cache()\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","LIBRARY_PATH = '/content/drive/MyDrive/NLP PROJECT/Finals/'\n","\n","# Seed\n","seed = 123\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","np.random.seed(seed)\n","random.seed(seed)\n","torch.backends.cudnn.benchmark = False\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"markdown","metadata":{"id":"RFsYbEgFEXYX"},"source":["## 1. Read and prepare data for training"]},{"cell_type":"code","source":["def clean_text(text, fixed_length = True, length = 256, head_len = 200, tail_len = 56):\n","  text = re.sub(r'http\\S+', '', text)\n","  text = re.sub(\"\\n|\\r\", \" \", text)\n","  text = re.sub(\"['']\", \"\", text)\n","\n","  if(fixed_length == True):\n","    tokens = text.split()\n","    if(len(tokens) > length):\n","      head = tokens[:head_len]\n","      tail = tokens[-tail_len:]\n","      text = ' '.join(head+tail)\n","\n","  return text\n"],"metadata":{"id":"lSH-HnE-fuT7"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z_eC8fRVL4FV"},"outputs":[],"source":["raw_data_path = LIBRARY_PATH + 'data/processed/'\n","raw_data_filename = 'train_DA.csv'\n","train_data = pd.read_csv(raw_data_path + raw_data_filename)\n"]},{"cell_type":"code","source":["## EDA \n","\n","## Check distribution of missing values\n","train_data.head()\n","eda_data1 = train_data[['link_id1', 'title1', 'text1', 'meta_keywords1', 'meta_description1']].drop_duplicates()\n","eda_data1.columns = ['ids', 'title', 'text', 'meta_keywords', 'meta_description']\n","eda_data2 = train_data[['link_id2', 'title2', 'text2', 'meta_keywords2', 'meta_description2']].drop_duplicates()\n","eda_data2.columns = ['ids', 'title', 'text', 'meta_keywords', 'meta_description']\n","\n","eda_df = pd.concat([eda_data1, eda_data2])\n","\n","## Print missing or blanks\n","# for meta_keywords\n","tmp = eda_df[ ~ ((eda_df['meta_keywords'] == '['']') | (eda_df['meta_keywords'] == ''))]\n","print(tmp['meta_keywords'].value_counts())\n","# [''], ''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WkEpEc0p4qI7","executionInfo":{"status":"ok","timestamp":1653865952837,"user_tz":420,"elapsed":948,"user":{"displayName":"Leo Ly","userId":"15125541943939299124"}},"outputId":"3d409cbe-36b6-49c0-c463-0838ca5367e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['']                                                                                                                                                                                                                                                             7693\n","[أ]                                                                                                                                                                                                                                                               243\n","['Schweriner Volkszeitung', 'Der Prignitzer', 'Norddeutsche Neueste Nachrichten', 'Nachrichten', 'News', 'Reportagen', 'Meldungen', 'Videos', 'Bilder']                                                                                                            31\n","['Nachrichten', 'Inland', 'Ausland', 'Wirtschaft', 'Sport', 'Kultur Reportage', 'Bericht', 'News', 'Tagesthemen', 'Aktuell', 'Neu', 'Neuigkeiten', 'Hintergrund', 'Hintergrund', 'Information', 'Politik', 'Innenpolitik', 'Aussenpolitik', 'Video', 'Audio']      17\n","['NRW', 'Polizei', 'Kriminalität', 'Presse', 'Pressemitteilung', 'Pressemeldung', 'Pressemitteilungen']                                                                                                                                                            15\n","                                                                                                                                                                                                                                                                 ... \n","[\"Hazem Imam\" ، \"Hazem أمام Zamalek\" ، \"Zamalek ، بطولة الدوري]                                                                                                                                                                                                     1\n","[\"مصطفى باكري\" ، \"وزارة الصحة\" ، \"كورونا فيروس\" ، \"تبديل الكاماس\" ، \"التدابير الوقائية\" ، \"الحقائق والأسرار\" ، \"صدى البلد\"]                                                                                                                                         1\n","[\"أرسنال\" ، \"كرة القدم\" ، \"كأس الاتحاد الإنجليزي\" ، \"]                                                                                                                                                                                                              1\n","[\"الاعتقال\" ، \"على\" ، \"al -maafin\" ، \"Brazen\" ، \"الوقاية\" ، \"Wander\"]                                                                                                                                                                                               1\n","['消息'， '']                                                                                                                                                                                                                                                          1\n","Name: meta_keywords, Length: 5988, dtype: int64\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1653865952838,"user":{"displayName":"Leo Ly","userId":"15125541943939299124"},"user_tz":420},"id":"3tMHzaz-H7Hp","outputId":"cffbbfe7-d5a0-459d-a8ed-d7840f4f27a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["After removing NA text columns, we lose 95 rows\n"]}],"source":["## Split into train and eval\n","\n","# remove na text from both the text fields\n","processed_data = train_data[train_data['text1'].notna()]\n","processed_data = processed_data[processed_data['text2'].notna()]\n","\n","print(\"After removing NA text columns, we lose {0} rows\".format(train_data.shape[0] - processed_data.shape[0]))"]},{"cell_type":"code","source":["def merge_clean_columns(df):\n","    \"\"\"\n","    Merge multiple columns into one and clean text\n","    \"\"\"  \n","    df['merge1'] = df['meta_keywords1'].astype(str) + ', ' \\\n","        + df['meta_description1'].astype(str) + ', '\\\n","        + df['title1'].astype(str) + ', '\\\n","        + df['text1'].astype(str)\n","\n","    df['merge2'] = df['meta_keywords2'].astype(str) + ', ' \\\n","        + df['meta_description2'].astype(str) + ', '\\\n","        + df['title2'].astype(str) + ', '\\\n","        + df['text2'].astype(str)\n","\n","    df['merge1'] = df['merge1'].apply(lambda x: clean_text(x))\n","    df['merge2'] = df['merge2'].apply(lambda x: clean_text(x))\n","\n","    return df"],"metadata":{"id":"V1JWq5jymzwr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["processed_data = merge_clean_columns(processed_data)\n","# split into train and development\n","train, dev = train_test_split(processed_data, test_size=0.1, random_state = 42)"],"metadata":{"id":"KNWWDBCcmwSh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tZMXmR0_QNzQ"},"source":["## 2. Model on data text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9NYsKPM8QKjF"},"outputs":[],"source":["## set parameters\n","max_len = 512\n","batch_size = 5\n","lr = 5e-6\n","weight_decay = 1e-4\n","num_epochs = 8"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LM33gaFg7rRE"},"outputs":[],"source":["def get_data_loader(data, batch_size_flg = True):\n","  tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n","  input_ids, attention_masks, labels = [], [], []\n","  for idx, row in data.iterrows():\n","      text1, text2 = row['merge1'], row['merge2']\n","      encode_dict = tokenizer(text1,text2,\n","                                  max_length=max_len,\n","                                  padding='max_length',\n","                                  truncation=True,\n","                                  add_special_tokens=True\n","                                  )\n","      \n","      input_ids.append(encode_dict['input_ids'])\n","      attention_masks.append(encode_dict['attention_mask'])\n","      # model is used to predict all labels?? -> should we convert to only 1 label\n","      labels.append([float(x) for x in [row['Geography'],row['Entities'],row['Time'],row['Narrative'],row['Overall'],row['Style'],row['Tone']]])\n","\n","  input_ids = torch.tensor(input_ids)\n","  attention_masks = torch.tensor(attention_masks)\n","  labels = torch.tensor(labels)\n","\n","  data = TensorDataset(input_ids, attention_masks, labels)\n","  if(batch_size_flg):\n","      data_loader = DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=True)\n","  else:\n","      data_loader = DataLoader(data)\n","  return data_loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vg56V9t08atc"},"outputs":[],"source":["train_data_loader = get_data_loader(train)\n","eval_data_loader = get_data_loader(dev, False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rTDTaFQmsA8O"},"outputs":[],"source":["class Custom_XLMRoberta(nn.Module):\n","    def __init__(self, model, hidden_size):\n","        super(Custom_XLMRoberta, self).__init__()\n","        self.reg_model = model\n","        self.fc1 = nn.Linear(hidden_size, 100)\n","        # self.dropout = nn.Dropout(0.2)\n","        self.fc2 = nn.Linear(100, 7) ## currently processes the 7 labels that we have defined for 7 output types\n","        self.activation = nn.GELU()\n","\n","    def forward(self, input_ids, attention_masks):\n","        output1 = self.reg_model(input_ids, attention_masks)[1]\n","        # output2 = \n","        # x = self.dropout(x)\n","        logits1 = self.fc2(self.activation(self.fc1(output1)))\n","        \n","        return logits1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oWuuxWC9wvSs"},"outputs":[],"source":["\n","def predict(model, data_loader):\n","  model.eval()\n","  overall_pred, overall_true = [], []\n","  with torch.no_grad():\n","    for idx, (ids, att_msks, y) in enumerate(data_loader):\n","      ids, att_msks, y = ids.to(device), att_msks.to(device), y.to(device)\n","      y_pred = model(ids, att_msks)\n","      y_pred, y = torch.squeeze(y_pred).cpu().numpy().tolist(), torch.squeeze(y).cpu().numpy().tolist()\n","      overall_pred.append(y_pred[4])\n","      overall_true.append(y[4])\n","  return overall_pred, overall_true\n","\n","\n","def weighted_loss( y_pred, y, criterion, loss_weights):\n","  loss = 0.0\n","  for i in range(7):\n","    y_pred_i, y_i = y_pred[:, i], y[:, i]\n","    loss += criterion(y_pred_i, y_i) * loss_weights[i]\n","  return loss\n","\n","\n","def train(model, model_path, train_data_loader, eval_data_loader, optimizer, loss_weights, epochs):\n","  model.train()\n","  criterion = nn.MSELoss()\n","  best_pearson = 0\n","  for i in range(epochs):\n","    train_loss_sum = 0\n","    for idx, (ids, att_msks, y) in enumerate(train_data_loader):\n","      ids, att_msks, y = ids.to(device), att_msks.to(device), y.to(device)\n","      optimizer.zero_grad()\n","      y_pred = model(ids, att_msks)\n","      y_pred, y = torch.squeeze(y_pred), torch.squeeze(y) ## required because y is a vector\n","      loss = weighted_loss(y_pred, y, criterion, loss_weights)\n","      loss.backward()\n","      optimizer.step()\n","      train_loss_sum += loss.item()\n","\n","    print(f\"Loss at epoch {i}: {train_loss_sum:.4f}\")\n","\n","    ## Determine best epoch model using correlation coefficient for Overall in dev data\n","    eval_pred_overall, eval_true_overall = predict(model, eval_data_loader)\n","    curr_pearson = np.corrcoef(eval_pred_overall, eval_true_overall)[0][1]\n","    print(curr_pearson)\n","    if curr_pearson > best_pearson:\n","      best_pearson = curr_pearson\n","      torch.save(model.state_dict(), model_path)\n","    \n"]},{"cell_type":"markdown","source":["### Training model"],"metadata":{"id":"loEOryJU53q8"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":453,"referenced_widgets":["d017b480100e4e4e8b9b04782cdf7f29","520d2a1b4b3b4e67886ed10fed842b0a","d6bffa9b84e443f0b79f410884842ef2","98f5bd39bcb949fd9ce2d2afe71daedb","59cecb769bd14806b5d16c28f72fd166","28767211287548408d6c38d6d47f6562","435aeaa4cb8d48d29837f9826098f551","4a31086e6a024ec5ad64e74e73962b61","f119c57d009941bbaed476dfd038dca9","f204a29ad95e4231bab13f07d19bf835","d335f0d59a0b42f0b204b01853f1a8bc"]},"id":"5ldBSUrA68uK","outputId":"0b3ca93d-7b05-4321-fa34-38b56d6b5318","executionInfo":{"status":"ok","timestamp":1653870078229,"user_tz":420,"elapsed":4022702,"user":{"displayName":"Leo Ly","userId":"15125541943939299124"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.04G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d017b480100e4e4e8b9b04782cdf7f29"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Loss at epoch 0: 2249.0445\n","0.6580801187528124\n","Loss at epoch 1: 1057.3436\n","0.8308381437938112\n","Loss at epoch 2: 874.1177\n","0.8389548556502878\n","Loss at epoch 3: 756.3701\n","0.8641544451296874\n","Loss at epoch 4: 654.5924\n","0.8728629775132095\n","Loss at epoch 5: 576.1322\n","0.8644985116585314\n","Loss at epoch 6: 503.5303\n","0.8786184662525112\n","Loss at epoch 7: 436.9448\n","0.8779098297235789\n"]}],"source":["## run model finetuning and save fine-tuned model\n","# pre_trained_model = XLMRobertaModel.from_pretrained(\"xlm-roberta-large\")\n","torch.cuda.empty_cache()\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","pre_trained_model = XLMRobertaModel.from_pretrained(\"xlm-roberta-base\")\n","config = XLMRobertaConfig.from_pretrained(\"xlm-roberta-base\")\n","hidden_size = config.hidden_size\n","# hidden_size = 768\n","overall_weight = 0.25\n","loss_weights = [overall_weight if i == 4 else (1-overall_weight)/6 for i in range(7)]\n","\n","model = Custom_XLMRoberta(pre_trained_model, hidden_size)\n","model.to(device)\n","\n","model_path = \"/content/drive/MyDrive/NLP PROJECT/Finals/ModelParams/XLM_Roberta_0.25_overall_loss.pth\"\n","# for iter in range(1,1000):\n","#     model_name = 'XLM_Roberta_base'\n","#     model_name_iter = f\"{model_name}_iter_{iter}.pth\"\n","#     model_path = f\"/content/drive/MyDrive/NLP PROJECT/Finals/ModelParams/{model_name_iter}\"\n","#     if not os.path.exists(model_path):\n","#       break\n","\n","# print(f\"Model name for this run: {model_name_iter}\")\n","\n","optimizer = AdamW(model.parameters(), lr=lr, weight_decay = weight_decay)\n","train(model, model_path, train_data_loader, eval_data_loader, optimizer, loss_weights, num_epochs)\n"]},{"cell_type":"markdown","metadata":{"id":"oTEe9rwjTP-e"},"source":["## 4. Evaluation on test data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ePvc8NygTyVN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653870102050,"user_tz":420,"elapsed":23825,"user":{"displayName":"Leo Ly","userId":"15125541943939299124"}},"outputId":"d60736ba-5b28-42d7-fc54-86b71a354438"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  if __name__ == '__main__':\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  # Remove the CWD from sys.path while we load stuff.\n"]}],"source":["#### Get data\n","data_path = LIBRARY_PATH + 'data/processed/'\n","filename = 'paired_eval.csv'\n","path = data_path + filename\n","tmp_file = pd.read_csv(path)\n","\n","tmp_file_new = tmp_file.drop_duplicates()\n","# Drop na for text 1 and text 2\n","test_dropna_text1 = tmp_file_new[tmp_file_new['text1'].notna()]\n","test_dropna_text1_2 = test_dropna_text1[test_dropna_text1['text2'].notna()]\n","# Merge data\n","processed_test_data = merge_clean_columns(test_dropna_text1_2)\n","\n","processed_test_data = processed_test_data.rename(columns = {'GEO': 'Geography', \\\n","                                                            'ENT': 'Entities', \\\n","                                                            'TIME': 'Time', \\\n","                                                            'NAR': 'Narrative', \\\n","                                                            'STYLE': 'Style', \\\n","                                                            'TONE': 'Tone'})\n","\n","\n","test_data_loader = get_data_loader(processed_test_data, False)\n","# row['Geography'],row['Entities'],row['Time'],row['Narrative'],row['Overall'],row['Style'],row['Tone']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M-uWOFA8TPRr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653870413244,"user_tz":420,"elapsed":311202,"user":{"displayName":"Leo Ly","userId":"15125541943939299124"}},"outputId":"fc9cba4f-6f52-49e7-c97c-27bf7eb2c790"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Pearson score on test dataset is 0.726\n","Pearson score on entire train dataset is 0.949\n"]}],"source":["config = XLMRobertaConfig.from_pretrained(\"xlm-roberta-base\")\n","hidden_size = config.hidden_size\n","\n","pre_trained_model = XLMRobertaModel.from_pretrained(\"xlm-roberta-base\")\n","model = Custom_XLMRoberta(pre_trained_model, hidden_size)\n","#model.load_state_dict(torch.load(model_path))\n","model.load_state_dict(torch.load(\"/content/drive/MyDrive/NLP PROJECT/Finals/ModelParams/XLM_Roberta_0.25_overall_loss.pth\"), strict=False)\n","model.to(device)\n","\n","test_pred_overall, test_true_overall = predict(model, test_data_loader)\n","test_pearson_score = np.corrcoef(test_pred_overall, test_true_overall)[0][1]\n","\n","print(\"Pearson score on test dataset is {:.3f}\".format(test_pearson_score))\n","\n","train_all = get_data_loader(processed_data, False)\n","train_pred_overall, train_true_overall = predict(model, train_all)\n","train_pearson_score = np.corrcoef(train_pred_overall, train_true_overall)[0][1]\n","print(\"Pearson score on entire train dataset is {:.3f}\".format(train_pearson_score))\n","\n"]},{"cell_type":"code","source":["train_all = get_data_loader(processed_data, False)\n","train_pred_overall, train_true_overall = predict(model, train_all)\n","train_pearson_score = np.corrcoef(train_pred_overall, train_true_overall)[0][1]\n","print(\"Pearson score on entire train dataset is {:.3f}\".format(train_pearson_score))"],"metadata":{"id":"DuKI986vowWv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653870609894,"user_tz":420,"elapsed":196654,"user":{"displayName":"Leo Ly","userId":"15125541943939299124"}},"outputId":"9236c7cc-8575-4d80-c046-c3af4aab123f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Pearson score on entire train dataset is 0.949\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"htrPeO9nGXMq"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"XLM-Roberta_0.25_overall.ipynb","provenance":[{"file_id":"11toR0uH7FiRrpKNFUdgQLc64pfC0WLKE","timestamp":1653794689739},{"file_id":"1EmE0K3fw37J0OB25YZPXJ6uDfZC4ZYLY","timestamp":1653433187544},{"file_id":"1Pq3JIgyEfq2Jv4I06UDTGVzg9EsCqh3K","timestamp":1653427277379}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d017b480100e4e4e8b9b04782cdf7f29":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_520d2a1b4b3b4e67886ed10fed842b0a","IPY_MODEL_d6bffa9b84e443f0b79f410884842ef2","IPY_MODEL_98f5bd39bcb949fd9ce2d2afe71daedb"],"layout":"IPY_MODEL_59cecb769bd14806b5d16c28f72fd166"}},"520d2a1b4b3b4e67886ed10fed842b0a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_28767211287548408d6c38d6d47f6562","placeholder":"​","style":"IPY_MODEL_435aeaa4cb8d48d29837f9826098f551","value":"Downloading: 100%"}},"d6bffa9b84e443f0b79f410884842ef2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a31086e6a024ec5ad64e74e73962b61","max":1115590446,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f119c57d009941bbaed476dfd038dca9","value":1115590446}},"98f5bd39bcb949fd9ce2d2afe71daedb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f204a29ad95e4231bab13f07d19bf835","placeholder":"​","style":"IPY_MODEL_d335f0d59a0b42f0b204b01853f1a8bc","value":" 1.04G/1.04G [00:39&lt;00:00, 38.5MB/s]"}},"59cecb769bd14806b5d16c28f72fd166":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28767211287548408d6c38d6d47f6562":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"435aeaa4cb8d48d29837f9826098f551":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a31086e6a024ec5ad64e74e73962b61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f119c57d009941bbaed476dfd038dca9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f204a29ad95e4231bab13f07d19bf835":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d335f0d59a0b42f0b204b01853f1a8bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}