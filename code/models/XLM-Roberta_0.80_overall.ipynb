{"cells":[{"cell_type":"markdown","metadata":{"id":"-4OUvVfQLgR4"},"source":["XLM-Roberta on multilingual text\n","- Training data + augmentation data\n","- Weighted loss = 80% Overall + (20% / 6) for each of the remaining 6 labels\n","- Model parameter file: XLM_Roberta_0.80_overall_loss.pth"]},{"cell_type":"markdown","metadata":{"id":"Bhj8tK3WESKl"},"source":["0. Install and import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q-Mlm41yMmLS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653857428672,"user_tz":420,"elapsed":22040,"user":{"displayName":"Leo Ly","userId":"15125541943939299124"}},"outputId":"48774ad4-4481-496b-f1f2-e3c150cffbdc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 8.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 27.4 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 58.0 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 1.6 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 6.4 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n"]}],"source":["## install libraries\n","\n","!pip install transformers\n","!pip install sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27385,"status":"ok","timestamp":1653857456049,"user":{"displayName":"Leo Ly","userId":"15125541943939299124"},"user_tz":420},"id":"lH_HtKSJLeWh","outputId":"29eeb560-0cbd-47ab-c761-0280030f4714"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import random\n","import json\n","import regex as re\n","\n","import matplotlib.pyplot as plt\n","import os\n","import sentencepiece\n","import torch\n","import torch.nn as nn\n","from transformers import AutoTokenizer\n","from transformers import AdamW\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import TensorDataset, DataLoader\n","from transformers import XLMRobertaConfig, XLMRobertaModel, XLMRobertaTokenizer\n","\n","torch.cuda.empty_cache()\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","LIBRARY_PATH = '/content/drive/MyDrive/NLP PROJECT/Finals/'\n","\n","# Seed\n","seed = 123\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","np.random.seed(seed)\n","random.seed(seed)\n","torch.backends.cudnn.benchmark = False\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"markdown","metadata":{"id":"RFsYbEgFEXYX"},"source":["## 1. Read and prepare data for training"]},{"cell_type":"code","source":["def clean_text(text, fixed_length = True, length = 256, head_len = 200, tail_len = 56):\n","  text = re.sub(r'http\\S+', '', text)\n","  text = re.sub(\"\\n|\\r\", \" \", text)\n","  text = re.sub(\"['']\", \"\", text)\n","\n","  if(fixed_length == True):\n","    tokens = text.split()\n","    if(len(tokens) > length):\n","      head = tokens[:head_len]\n","      tail = tokens[-tail_len:]\n","      text = ' '.join(head+tail)\n","\n","  return text\n"],"metadata":{"id":"lSH-HnE-fuT7"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z_eC8fRVL4FV"},"outputs":[],"source":["raw_data_path = LIBRARY_PATH + 'data/processed/'\n","raw_data_filename = 'train_DA.csv'\n","train_data = pd.read_csv(raw_data_path + raw_data_filename)\n"]},{"cell_type":"code","source":["## EDA \n","\n","## Check distribution of missing values\n","train_data.head()\n","eda_data1 = train_data[['link_id1', 'title1', 'text1', 'meta_keywords1', 'meta_description1']].drop_duplicates()\n","eda_data1.columns = ['ids', 'title', 'text', 'meta_keywords', 'meta_description']\n","eda_data2 = train_data[['link_id2', 'title2', 'text2', 'meta_keywords2', 'meta_description2']].drop_duplicates()\n","eda_data2.columns = ['ids', 'title', 'text', 'meta_keywords', 'meta_description']\n","\n","eda_df = pd.concat([eda_data1, eda_data2])\n","\n","## Print missing or blanks\n","# for meta_keywords\n","tmp = eda_df[ ~ ((eda_df['meta_keywords'] == '['']') | (eda_df['meta_keywords'] == ''))]\n","print(tmp['meta_keywords'].value_counts())\n","# [''], ''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WkEpEc0p4qI7","executionInfo":{"status":"ok","timestamp":1653857458519,"user_tz":420,"elapsed":20,"user":{"displayName":"Leo Ly","userId":"15125541943939299124"}},"outputId":"429a5285-6f79-4fe8-e583-104270633875"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['']                                                                                                                                                                                                                                                             7693\n","[أ]                                                                                                                                                                                                                                                               243\n","['Schweriner Volkszeitung', 'Der Prignitzer', 'Norddeutsche Neueste Nachrichten', 'Nachrichten', 'News', 'Reportagen', 'Meldungen', 'Videos', 'Bilder']                                                                                                            31\n","['Nachrichten', 'Inland', 'Ausland', 'Wirtschaft', 'Sport', 'Kultur Reportage', 'Bericht', 'News', 'Tagesthemen', 'Aktuell', 'Neu', 'Neuigkeiten', 'Hintergrund', 'Hintergrund', 'Information', 'Politik', 'Innenpolitik', 'Aussenpolitik', 'Video', 'Audio']      17\n","['NRW', 'Polizei', 'Kriminalität', 'Presse', 'Pressemitteilung', 'Pressemeldung', 'Pressemitteilungen']                                                                                                                                                            15\n","                                                                                                                                                                                                                                                                 ... \n","[\"Hazem Imam\" ، \"Hazem أمام Zamalek\" ، \"Zamalek ، بطولة الدوري]                                                                                                                                                                                                     1\n","[\"مصطفى باكري\" ، \"وزارة الصحة\" ، \"كورونا فيروس\" ، \"تبديل الكاماس\" ، \"التدابير الوقائية\" ، \"الحقائق والأسرار\" ، \"صدى البلد\"]                                                                                                                                         1\n","[\"أرسنال\" ، \"كرة القدم\" ، \"كأس الاتحاد الإنجليزي\" ، \"]                                                                                                                                                                                                              1\n","[\"الاعتقال\" ، \"على\" ، \"al -maafin\" ، \"Brazen\" ، \"الوقاية\" ، \"Wander\"]                                                                                                                                                                                               1\n","['消息'， '']                                                                                                                                                                                                                                                          1\n","Name: meta_keywords, Length: 5988, dtype: int64\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1653857458519,"user":{"displayName":"Leo Ly","userId":"15125541943939299124"},"user_tz":420},"id":"3tMHzaz-H7Hp","outputId":"b7f9a460-6588-409e-848b-ebbf07d0a457"},"outputs":[{"output_type":"stream","name":"stdout","text":["After removing NA text columns, we lose 95 rows\n"]}],"source":["## Split into train and eval\n","\n","# remove na text from both the text fields\n","processed_data = train_data[train_data['text1'].notna()]\n","processed_data = processed_data[processed_data['text2'].notna()]\n","\n","print(\"After removing NA text columns, we lose {0} rows\".format(train_data.shape[0] - processed_data.shape[0]))"]},{"cell_type":"code","source":["def merge_clean_columns(df):\n","    \"\"\"\n","    Merge multiple columns into one and clean text\n","    \"\"\"  \n","    df['merge1'] = df['meta_keywords1'].astype(str) + ', ' \\\n","        + df['meta_description1'].astype(str) + ', '\\\n","        + df['title1'].astype(str) + ', '\\\n","        + df['text1'].astype(str)\n","\n","    df['merge2'] = df['meta_keywords2'].astype(str) + ', ' \\\n","        + df['meta_description2'].astype(str) + ', '\\\n","        + df['title2'].astype(str) + ', '\\\n","        + df['text2'].astype(str)\n","\n","    df['merge1'] = df['merge1'].apply(lambda x: clean_text(x))\n","    df['merge2'] = df['merge2'].apply(lambda x: clean_text(x))\n","\n","    return df"],"metadata":{"id":"V1JWq5jymzwr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["processed_data = merge_clean_columns(processed_data)\n","# split into train and development\n","train, dev = train_test_split(processed_data, test_size=0.1, random_state = 42)"],"metadata":{"id":"KNWWDBCcmwSh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tZMXmR0_QNzQ"},"source":["## 2. Model on data text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9NYsKPM8QKjF"},"outputs":[],"source":["## set parameters\n","max_len = 512\n","batch_size = 5\n","lr = 5e-6\n","weight_decay = 1e-4\n","num_epochs = 8"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LM33gaFg7rRE"},"outputs":[],"source":["def get_data_loader(data, batch_size_flg = True):\n","  tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n","  input_ids, attention_masks, labels = [], [], []\n","  for idx, row in data.iterrows():\n","      text1, text2 = row['merge1'], row['merge2']\n","      encode_dict = tokenizer(text1,text2,\n","                                  max_length=max_len,\n","                                  padding='max_length',\n","                                  truncation=True,\n","                                  add_special_tokens=True\n","                                  )\n","      \n","      input_ids.append(encode_dict['input_ids'])\n","      attention_masks.append(encode_dict['attention_mask'])\n","      # model is used to predict all labels?? -> should we convert to only 1 label\n","      labels.append([float(x) for x in [row['Geography'],row['Entities'],row['Time'],row['Narrative'],row['Overall'],row['Style'],row['Tone']]])\n","\n","  input_ids = torch.tensor(input_ids)\n","  attention_masks = torch.tensor(attention_masks)\n","  labels = torch.tensor(labels)\n","\n","  data = TensorDataset(input_ids, attention_masks, labels)\n","  if(batch_size_flg):\n","      data_loader = DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=True)\n","  else:\n","      data_loader = DataLoader(data)\n","  return data_loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vg56V9t08atc","colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["7187dbf602774aa8aedf9e40524304ff","889e4b8391954219bbc487f21ae1ae64","34984910e61847f480f90fcd7ebe7839","86f6ac14c1ee4eb1acdd2d3d467fb321","783db78fa0ee4a36b6a66ce48b65aedd","42e1337046b14e2195e0094b4d95b4ad","3d65490678fc4eaf99ae0041b227f4a8","67fb8e72528247af8ae2529a7d93d632","a6096a7e215c407badc79f8c7a8d27b0","5c60e31572ea47eaa86c7da7bb330376","31c519a360854deeb18373be87a89427","43005123f557495b8c140ec2a5242e67","b5b8b7ea998c44829bd092d8aa38493b","4a6bb49b96364bec826a03eb7b1cd166","d01f93bd540d41728432fd96d9603674","d27f264d5aea4c5bada529a30224ed08","6abca8ec1a944e90a59fd53830665501","a93d353a4cc34a8cb986991a99d31324","102b7fca79594128bddca02bbcb62367","bdf3d70997e04f26971312f4ccf102fc","e4b7d2147b614a38bb6d50426ac48dde","62fbb010801649e58ce5136ed975501b","82d58b3b5437418b8708b48ace0d220b","08b0d9c022b54f23820fdd413cff9283","d68f1055967643dd8cee761829186fa3","08fc16b4f8ab4d0083ada41f10973160","7f316dd991a743d5aeef2697b65e62f4","e7def843332245b1bf98abcccfa30e83","992b269f783f42e3808a9657bf44768d","2e1583c39b9b40dcaf97c7c035e06831","26c46c660c6d48d8ba00ca78e5225a4b","6998d071881c4bccb15d89cf0165ffe2","db949ffd577f48ba9acfb089e249eeba"]},"outputId":"a563b147-c3cf-4764-bf41-5a2ff2495322","executionInfo":{"status":"ok","timestamp":1653857510934,"user_tz":420,"elapsed":48204,"user":{"displayName":"Leo Ly","userId":"15125541943939299124"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/615 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7187dbf602774aa8aedf9e40524304ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43005123f557495b8c140ec2a5242e67"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82d58b3b5437418b8708b48ace0d220b"}},"metadata":{}}],"source":["train_data_loader = get_data_loader(train)\n","eval_data_loader = get_data_loader(dev, False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rTDTaFQmsA8O"},"outputs":[],"source":["class Custom_XLMRoberta(nn.Module):\n","    def __init__(self, model, hidden_size):\n","        super(Custom_XLMRoberta, self).__init__()\n","        self.reg_model = model\n","        self.fc1 = nn.Linear(hidden_size, 100)\n","        # self.dropout = nn.Dropout(0.2)\n","        self.fc2 = nn.Linear(100, 7) ## currently processes the 7 labels that we have defined for 7 output types\n","        self.activation = nn.GELU()\n","\n","    def forward(self, input_ids, attention_masks):\n","        output1 = self.reg_model(input_ids, attention_masks)[1]\n","        # output2 = \n","        # x = self.dropout(x)\n","        logits1 = self.fc2(self.activation(self.fc1(output1)))\n","        \n","        return logits1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oWuuxWC9wvSs"},"outputs":[],"source":["\n","def predict(model, data_loader):\n","  model.eval()\n","  overall_pred, overall_true = [], []\n","  with torch.no_grad():\n","    for idx, (ids, att_msks, y) in enumerate(data_loader):\n","      ids, att_msks, y = ids.to(device), att_msks.to(device), y.to(device)\n","      y_pred = model(ids, att_msks)\n","      y_pred, y = torch.squeeze(y_pred).cpu().numpy().tolist(), torch.squeeze(y).cpu().numpy().tolist()\n","      overall_pred.append(y_pred[4])\n","      overall_true.append(y[4])\n","  return overall_pred, overall_true\n","\n","\n","def weighted_loss( y_pred, y, criterion, loss_weights):\n","  loss = 0.0\n","  for i in range(7):\n","    y_pred_i, y_i = y_pred[:, i], y[:, i]\n","    loss += criterion(y_pred_i, y_i) * loss_weights[i]\n","  return loss\n","\n","\n","def train(model, model_path, train_data_loader, eval_data_loader, optimizer, loss_weights, epochs):\n","  model.train()\n","  criterion = nn.MSELoss()\n","  best_pearson = 0\n","  for i in range(epochs):\n","    train_loss_sum = 0\n","    for idx, (ids, att_msks, y) in enumerate(train_data_loader):\n","      ids, att_msks, y = ids.to(device), att_msks.to(device), y.to(device)\n","      optimizer.zero_grad()\n","      y_pred = model(ids, att_msks)\n","      y_pred, y = torch.squeeze(y_pred), torch.squeeze(y) ## required because y is a vector\n","      loss = weighted_loss(y_pred, y, criterion, loss_weights)\n","      loss.backward()\n","      optimizer.step()\n","      train_loss_sum += loss.item()\n","\n","    print(f\"Loss at epoch {i}: {train_loss_sum:.4f}\")\n","\n","    ## Determine best epoch model using correlation coefficient for Overall in dev data\n","    eval_pred_overall, eval_true_overall = predict(model, eval_data_loader)\n","    curr_pearson = np.corrcoef(eval_pred_overall, eval_true_overall)[0][1]\n","    print(curr_pearson)\n","    if curr_pearson > best_pearson:\n","      best_pearson = curr_pearson\n","      torch.save(model.state_dict(), model_path)\n","    \n"]},{"cell_type":"markdown","source":["### Training model"],"metadata":{"id":"loEOryJU53q8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5ldBSUrA68uK","colab":{"base_uri":"https://localhost:8080/","height":471,"referenced_widgets":["d1dbe4823c2b4cc8a2ef519d9d99f269","62ff066a20a9415bb29d5c337c1c74ea","35ccb0ca800d46938dd36f8f4ff0bbfc","ffa96ae35ec843bcb377d379b880f7d0","d964973cf7bd45c2910999152e61a2fb","2d57e951f1894de58bedb37a89386f6a","e36c41f29c1a4910ba75e7336c597593","d67b3e00fa5e44b3a768e491bc04b189","aae8e35f887e4132b15db21f79522150","b01c91e707024b0d8ad34163e2a7f976","a0253d6514974fc1b2d67c32dfb236d2"]},"executionInfo":{"status":"ok","timestamp":1653861535915,"user_tz":420,"elapsed":4024774,"user":{"displayName":"Leo Ly","userId":"15125541943939299124"}},"outputId":"6b6b318c-6bcf-448a-fc60-1e84b4e6f9c8"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.04G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1dbe4823c2b4cc8a2ef519d9d99f269"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Model name for this run: XLM_Roberta_base_iter_4.pth\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Loss at epoch 0: 2397.1774\n","0.7357687971558542\n","Loss at epoch 1: 885.2857\n","0.8291429125606392\n","Loss at epoch 2: 633.2820\n","0.8455705593611827\n","Loss at epoch 3: 471.7975\n","0.8617311531597066\n","Loss at epoch 4: 373.9086\n","0.8579806591902556\n","Loss at epoch 5: 312.9722\n","0.8676998963736328\n","Loss at epoch 6: 278.1813\n","0.8737556287416061\n","Loss at epoch 7: 248.4891\n","0.8754657007837116\n"]}],"source":["## run model finetuning and save fine-tuned model\n","# pre_trained_model = XLMRobertaModel.from_pretrained(\"xlm-roberta-large\")\n","torch.cuda.empty_cache()\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","pre_trained_model = XLMRobertaModel.from_pretrained(\"xlm-roberta-base\")\n","config = XLMRobertaConfig.from_pretrained(\"xlm-roberta-base\")\n","hidden_size = config.hidden_size\n","# hidden_size = 768\n","overall_weight = 0.8\n","loss_weights = [overall_weight if i == 4 else (1-overall_weight)/6 for i in range(7)]\n","\n","model = Custom_XLMRoberta(pre_trained_model, hidden_size)\n","model.to(device)\n","\n","\n","for iter in range(1,1000):\n","    model_name = 'XLM_Roberta_base'\n","    model_name_iter = f\"{model_name}_iter_{iter}.pth\"\n","    model_path = f\"/content/drive/MyDrive/NLP PROJECT/Finals/ModelParams/{model_name_iter}\"\n","    if not os.path.exists(model_path):\n","      break\n","\n","print(f\"Model name for this run: {model_name_iter}\")\n","\n","optimizer = AdamW(model.parameters(), lr=lr, weight_decay = weight_decay)\n","train(model, model_path, train_data_loader, eval_data_loader, optimizer, loss_weights, num_epochs)\n"]},{"cell_type":"markdown","metadata":{"id":"oTEe9rwjTP-e"},"source":["## 4. Evaluation on test data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ePvc8NygTyVN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653861558440,"user_tz":420,"elapsed":22528,"user":{"displayName":"Leo Ly","userId":"15125541943939299124"}},"outputId":"6ebbb092-8bc9-4845-83fc-5f9c7e2456ba"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  if __name__ == '__main__':\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  # Remove the CWD from sys.path while we load stuff.\n"]}],"source":["#### Get data\n","data_path = LIBRARY_PATH + 'data/processed/'\n","filename = 'paired_eval.csv'\n","path = data_path + filename\n","tmp_file = pd.read_csv(path)\n","\n","tmp_file_new = tmp_file.drop_duplicates()\n","# Drop na for text 1 and text 2\n","test_dropna_text1 = tmp_file_new[tmp_file_new['text1'].notna()]\n","test_dropna_text1_2 = test_dropna_text1[test_dropna_text1['text2'].notna()]\n","# Merge data\n","processed_test_data = merge_clean_columns(test_dropna_text1_2)\n","\n","processed_test_data = processed_test_data.rename(columns = {'GEO': 'Geography', \\\n","                                                            'ENT': 'Entities', \\\n","                                                            'TIME': 'Time', \\\n","                                                            'NAR': 'Narrative', \\\n","                                                            'STYLE': 'Style', \\\n","                                                            'TONE': 'Tone'})\n","\n","\n","test_data_loader = get_data_loader(processed_test_data, False)\n","# row['Geography'],row['Entities'],row['Time'],row['Narrative'],row['Overall'],row['Style'],row['Tone']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M-uWOFA8TPRr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653861859185,"user_tz":420,"elapsed":300756,"user":{"displayName":"Leo Ly","userId":"15125541943939299124"}},"outputId":"c9705c0e-a8e7-4785-c3c1-473da90bed81"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Pearson score on test dataset is 0.723\n","Pearson score on entire train dataset is 0.972\n"]}],"source":["config = XLMRobertaConfig.from_pretrained(\"xlm-roberta-base\")\n","hidden_size = config.hidden_size\n","\n","pre_trained_model = XLMRobertaModel.from_pretrained(\"xlm-roberta-base\")\n","model = Custom_XLMRoberta(pre_trained_model, hidden_size)\n","#model.load_state_dict(torch.load(model_path))\n","model.load_state_dict(torch.load(\"/content/drive/MyDrive/NLP PROJECT/Finals/ModelParams/XLM_Roberta_0.80_overall_loss.pth\"), strict=False)\n","model.to(device)\n","\n","test_pred_overall, test_true_overall = predict(model, test_data_loader)\n","test_pearson_score = np.corrcoef(test_pred_overall, test_true_overall)[0][1]\n","\n","print(\"Pearson score on test dataset is {:.3f}\".format(test_pearson_score))\n","\n","train_all = get_data_loader(processed_data, False)\n","train_pred_overall, train_true_overall = predict(model, train_all)\n","train_pearson_score = np.corrcoef(train_pred_overall, train_true_overall)[0][1]\n","print(\"Pearson score on entire train dataset is {:.3f}\".format(train_pearson_score))\n","\n"]},{"cell_type":"code","source":["train_all = get_data_loader(processed_data, False)\n","train_pred_overall, train_true_overall = predict(model, train_all)\n","train_pearson_score = np.corrcoef(train_pred_overall, train_true_overall)[0][1]\n","print(\"Pearson score on entire train dataset is {:.3f}\".format(train_pearson_score))"],"metadata":{"id":"DuKI986vowWv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653862046881,"user_tz":420,"elapsed":187706,"user":{"displayName":"Leo Ly","userId":"15125541943939299124"}},"outputId":"e12401bc-50e3-447c-9a38-40b41daf7d91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Pearson score on entire train dataset is 0.972\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"16nWJElElnr7"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"XLM-Roberta_0.80_overall.ipynb","provenance":[{"file_id":"11toR0uH7FiRrpKNFUdgQLc64pfC0WLKE","timestamp":1653794689739},{"file_id":"1EmE0K3fw37J0OB25YZPXJ6uDfZC4ZYLY","timestamp":1653433187544},{"file_id":"1Pq3JIgyEfq2Jv4I06UDTGVzg9EsCqh3K","timestamp":1653427277379}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"7187dbf602774aa8aedf9e40524304ff":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_889e4b8391954219bbc487f21ae1ae64","IPY_MODEL_34984910e61847f480f90fcd7ebe7839","IPY_MODEL_86f6ac14c1ee4eb1acdd2d3d467fb321"],"layout":"IPY_MODEL_783db78fa0ee4a36b6a66ce48b65aedd"}},"889e4b8391954219bbc487f21ae1ae64":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_42e1337046b14e2195e0094b4d95b4ad","placeholder":"​","style":"IPY_MODEL_3d65490678fc4eaf99ae0041b227f4a8","value":"Downloading: 100%"}},"34984910e61847f480f90fcd7ebe7839":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_67fb8e72528247af8ae2529a7d93d632","max":615,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a6096a7e215c407badc79f8c7a8d27b0","value":615}},"86f6ac14c1ee4eb1acdd2d3d467fb321":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c60e31572ea47eaa86c7da7bb330376","placeholder":"​","style":"IPY_MODEL_31c519a360854deeb18373be87a89427","value":" 615/615 [00:00&lt;00:00, 3.35kB/s]"}},"783db78fa0ee4a36b6a66ce48b65aedd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42e1337046b14e2195e0094b4d95b4ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d65490678fc4eaf99ae0041b227f4a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67fb8e72528247af8ae2529a7d93d632":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6096a7e215c407badc79f8c7a8d27b0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5c60e31572ea47eaa86c7da7bb330376":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31c519a360854deeb18373be87a89427":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"43005123f557495b8c140ec2a5242e67":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b5b8b7ea998c44829bd092d8aa38493b","IPY_MODEL_4a6bb49b96364bec826a03eb7b1cd166","IPY_MODEL_d01f93bd540d41728432fd96d9603674"],"layout":"IPY_MODEL_d27f264d5aea4c5bada529a30224ed08"}},"b5b8b7ea998c44829bd092d8aa38493b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6abca8ec1a944e90a59fd53830665501","placeholder":"​","style":"IPY_MODEL_a93d353a4cc34a8cb986991a99d31324","value":"Downloading: 100%"}},"4a6bb49b96364bec826a03eb7b1cd166":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_102b7fca79594128bddca02bbcb62367","max":5069051,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bdf3d70997e04f26971312f4ccf102fc","value":5069051}},"d01f93bd540d41728432fd96d9603674":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4b7d2147b614a38bb6d50426ac48dde","placeholder":"​","style":"IPY_MODEL_62fbb010801649e58ce5136ed975501b","value":" 4.83M/4.83M [00:00&lt;00:00, 8.34MB/s]"}},"d27f264d5aea4c5bada529a30224ed08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6abca8ec1a944e90a59fd53830665501":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a93d353a4cc34a8cb986991a99d31324":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"102b7fca79594128bddca02bbcb62367":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdf3d70997e04f26971312f4ccf102fc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e4b7d2147b614a38bb6d50426ac48dde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62fbb010801649e58ce5136ed975501b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82d58b3b5437418b8708b48ace0d220b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_08b0d9c022b54f23820fdd413cff9283","IPY_MODEL_d68f1055967643dd8cee761829186fa3","IPY_MODEL_08fc16b4f8ab4d0083ada41f10973160"],"layout":"IPY_MODEL_7f316dd991a743d5aeef2697b65e62f4"}},"08b0d9c022b54f23820fdd413cff9283":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7def843332245b1bf98abcccfa30e83","placeholder":"​","style":"IPY_MODEL_992b269f783f42e3808a9657bf44768d","value":"Downloading: 100%"}},"d68f1055967643dd8cee761829186fa3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e1583c39b9b40dcaf97c7c035e06831","max":9096718,"min":0,"orientation":"horizontal","style":"IPY_MODEL_26c46c660c6d48d8ba00ca78e5225a4b","value":9096718}},"08fc16b4f8ab4d0083ada41f10973160":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6998d071881c4bccb15d89cf0165ffe2","placeholder":"​","style":"IPY_MODEL_db949ffd577f48ba9acfb089e249eeba","value":" 8.68M/8.68M [00:00&lt;00:00, 19.3MB/s]"}},"7f316dd991a743d5aeef2697b65e62f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7def843332245b1bf98abcccfa30e83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"992b269f783f42e3808a9657bf44768d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e1583c39b9b40dcaf97c7c035e06831":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26c46c660c6d48d8ba00ca78e5225a4b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6998d071881c4bccb15d89cf0165ffe2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db949ffd577f48ba9acfb089e249eeba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1dbe4823c2b4cc8a2ef519d9d99f269":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_62ff066a20a9415bb29d5c337c1c74ea","IPY_MODEL_35ccb0ca800d46938dd36f8f4ff0bbfc","IPY_MODEL_ffa96ae35ec843bcb377d379b880f7d0"],"layout":"IPY_MODEL_d964973cf7bd45c2910999152e61a2fb"}},"62ff066a20a9415bb29d5c337c1c74ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d57e951f1894de58bedb37a89386f6a","placeholder":"​","style":"IPY_MODEL_e36c41f29c1a4910ba75e7336c597593","value":"Downloading: 100%"}},"35ccb0ca800d46938dd36f8f4ff0bbfc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d67b3e00fa5e44b3a768e491bc04b189","max":1115590446,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aae8e35f887e4132b15db21f79522150","value":1115590446}},"ffa96ae35ec843bcb377d379b880f7d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b01c91e707024b0d8ad34163e2a7f976","placeholder":"​","style":"IPY_MODEL_a0253d6514974fc1b2d67c32dfb236d2","value":" 1.04G/1.04G [00:55&lt;00:00, 27.3MB/s]"}},"d964973cf7bd45c2910999152e61a2fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d57e951f1894de58bedb37a89386f6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e36c41f29c1a4910ba75e7336c597593":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d67b3e00fa5e44b3a768e491bc04b189":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aae8e35f887e4132b15db21f79522150":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b01c91e707024b0d8ad34163e2a7f976":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0253d6514974fc1b2d67c32dfb236d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}